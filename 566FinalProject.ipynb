{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "urgkQBL6CrXj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "train = '/content/drive/MyDrive/566FinalProject/Problem_6_SLO_Fundus_Cup_and_Disc_Segmentation/FairSeg/Training'\n",
        "test = '/content/drive/MyDrive/566FinalProject/Problem_6_SLO_Fundus_Cup_and_Disc_Segmentation/FairSeg/Testing'\n",
        "\n",
        "trainfiles = glob.glob(train + '/*.npz')\n",
        "testfiles = glob.glob(test + '/*.npz')\n",
        "\n",
        "def load(files):\n",
        "    fundus, mask, other = [], [], []\n",
        "    for f in files:\n",
        "        d = dict(np.load(f, allow_pickle=True))\n",
        "        fundus_img = d['slo_fundus']\n",
        "        mask_img = d['disc_cup_mask']\n",
        "        mask_img = np.where(mask_img == -2, 2, np.where(mask_img == -1, 1, 0)).astype(np.uint8)\n",
        "        fundus.append(fundus_img)\n",
        "        mask.append(mask_img)\n",
        "        other.append({\n",
        "            'file': f,\n",
        "            'age': float(d['age']),\n",
        "            'gender': str(d['gender']),\n",
        "            'race': str(d['race'])\n",
        "        })\n",
        "    return fundus, mask, other\n",
        "\n",
        "train_fundus, train_mask, train_data = load(trainfiles)\n",
        "test_fundus, test_mask, test_data = load(testfiles)\n",
        "\n",
        "print(\"Training files:\", len(train_fundus))\n",
        "print(\"Testing files:\", len(test_fundus))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWcjiBnYkolK",
        "outputId": "1985e4f0-05aa-4f9a-cb20-d6c1ead53769"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training files: 1000\n",
            "Testing files: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "preprocess_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "preprocess_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "IMG_SIZE = 256\n",
        "\n",
        "def resize_data(images, masks):\n",
        "    x, y = [], []\n",
        "    for img, mask in zip(images, masks):\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "        x.append(img)\n",
        "        y.append(mask)\n",
        "    return np.expand_dims(np.array(x), -1), np.array(y)\n",
        "\n",
        "train_fundus, train_mask = resize_data(train_fundus, train_mask)\n",
        "test_fundus, test_mask = resize_data(test_fundus, test_mask)\n",
        "\n",
        "train_mask = tf.keras.utils.to_categorical(train_mask, num_classes=3)\n",
        "test_mask = tf.keras.utils.to_categorical(test_mask, num_classes=3)\n",
        "\n",
        "train_img = preprocess_train.flow(train_fundus, train_mask, batch_size=10, shuffle=True)\n",
        "test_img = preprocess_test.flow(test_fundus, test_mask, batch_size=10, shuffle=False)\n"
      ],
      "metadata": {
        "id": "XaVhyIimz6ra"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_fundus.shape)\n",
        "print(test_fundus.shape)\n",
        "print(train_mask.shape)\n",
        "print(test_mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N72_qSq6-qoV",
        "outputId": "bc0614c2-3b9f-4512-fb8a-8005aa2d203b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 256, 256, 1)\n",
            "(500, 256, 256, 1)\n",
            "(1000, 256, 256, 3)\n",
            "(500, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#UNET\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def encoder(inputs):\n",
        "  c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "  c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
        "  p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "  c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
        "  c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
        "  p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
        "  c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(c3)\n",
        "  p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
        "  c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(c4)\n",
        "  p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "  return p4, [c1, c2, c3, c4]\n",
        "\n",
        "def decoder(inputs, skips):\n",
        "  c1, c2, c3, c4 = skips\n",
        "\n",
        "  d1 = layers.UpSampling2D((2, 2))(inputs)\n",
        "  d1 = layers.concatenate([d1, c4])\n",
        "  c5 = layers.Conv2D(512, 3, activation='relu', padding='same')(d1)\n",
        "  c5 = layers.Conv2D(512, 3, activation='relu', padding='same')(c5)\n",
        "\n",
        "  d2 = layers.UpSampling2D((2, 2))(c5)\n",
        "  d2 = layers.concatenate([d2, c3])\n",
        "  c6 = layers.Conv2D(256, 3, activation='relu', padding='same')(d2)\n",
        "  c6 = layers.Conv2D(256, 3, activation='relu', padding='same')(c6)\n",
        "\n",
        "  d3 = layers.UpSampling2D((2, 2))(c6)\n",
        "  d3 = layers.concatenate([d3, c2])\n",
        "  c7 = layers.Conv2D(128, 3, activation='relu', padding='same')(d3)\n",
        "  c7 = layers.Conv2D(128, 3, activation='relu', padding='same')(c7)\n",
        "\n",
        "  d4 = layers.UpSampling2D((2, 2))(c7)\n",
        "  d4 = layers.concatenate([d4, c1])\n",
        "  c8 = layers.Conv2D(64, 3, activation='relu', padding='same')(d4)\n",
        "  c8 = layers.Conv2D(64, 3, activation='relu', padding='same')(c8)\n",
        "\n",
        "  return c8\n",
        "\n",
        "def unet_model(input_shape=(256, 256, 1)):\n",
        "  inputs = layers.Input(input_shape)\n",
        "  b_input, skips = encoder(inputs)\n",
        "  b = layers.Conv2D(1024, 3, activation='relu', padding='same')(b_input)\n",
        "  b = layers.Conv2D(1024, 3, activation='relu', padding='same')(b)\n",
        "\n",
        "  dec = decoder(b, skips)\n",
        "  outputs = layers.Conv2D(3, 1, activation='softmax')(dec)\n",
        "\n",
        "  return models.Model(inputs=[inputs], outputs=[outputs])\n"
      ],
      "metadata": {
        "id": "NT4w9pRN-5pS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_accuracy',\n",
        "    patience = 5,\n",
        "    restore_best_weights = 'True'\n",
        ")\n",
        "\n",
        "model = unet_model(input_shape=(256,256,1))\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "\n",
        ")\n",
        "\n",
        "history = model.fit(train_img, validation_data=test_img,  callbacks = [early_stopping], epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2aqeqSiGNiQ",
        "outputId": "a611a9c7-ded0-412f-f733-d760e062202b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 92ms/step - accuracy: 0.9270 - loss: 0.4367 - val_accuracy: 0.9776 - val_loss: 0.0527\n",
            "Epoch 2/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.9772 - loss: 0.0614 - val_accuracy: 0.9776 - val_loss: 0.0452\n",
            "Epoch 3/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.9780 - loss: 0.0534 - val_accuracy: 0.9866 - val_loss: 0.0346\n",
            "Epoch 4/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9817 - loss: 0.0453 - val_accuracy: 0.9902 - val_loss: 0.0303\n",
            "Epoch 5/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - accuracy: 0.9823 - loss: 0.0441 - val_accuracy: 0.9891 - val_loss: 0.0346\n",
            "Epoch 6/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9834 - loss: 0.0414 - val_accuracy: 0.9908 - val_loss: 0.0282\n",
            "Epoch 7/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9828 - loss: 0.0425 - val_accuracy: 0.9898 - val_loss: 0.0311\n",
            "Epoch 8/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.9832 - loss: 0.0415 - val_accuracy: 0.9920 - val_loss: 0.0288\n",
            "Epoch 9/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9835 - loss: 0.0414 - val_accuracy: 0.9919 - val_loss: 0.0257\n",
            "Epoch 10/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.9832 - loss: 0.0415 - val_accuracy: 0.9921 - val_loss: 0.0254\n",
            "Epoch 11/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9837 - loss: 0.0395 - val_accuracy: 0.9911 - val_loss: 0.0287\n",
            "Epoch 12/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.9838 - loss: 0.0396 - val_accuracy: 0.9915 - val_loss: 0.0283\n",
            "Epoch 13/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.9833 - loss: 0.0404 - val_accuracy: 0.9921 - val_loss: 0.0243\n",
            "Epoch 14/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9847 - loss: 0.0372 - val_accuracy: 0.9916 - val_loss: 0.0276\n",
            "Epoch 15/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9840 - loss: 0.0378 - val_accuracy: 0.9917 - val_loss: 0.0246\n",
            "Epoch 16/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9844 - loss: 0.0376 - val_accuracy: 0.9915 - val_loss: 0.0260\n",
            "Epoch 17/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9841 - loss: 0.0373 - val_accuracy: 0.9917 - val_loss: 0.0261\n",
            "Epoch 18/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.9848 - loss: 0.0354 - val_accuracy: 0.9911 - val_loss: 0.0274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def dice_coef_per_class(y_true, y_pred, smooth=1e-6):\n",
        "    dices = []\n",
        "    for c in range(y_true.shape[-1]):\n",
        "        y_true_f = y_true[..., c].flatten()\n",
        "        y_pred_f = y_pred[..., c].flatten()\n",
        "        intersection = np.sum(y_true_f * y_pred_f)\n",
        "        dice = (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "        dices.append(dice)\n",
        "    return np.mean(dices)\n",
        "\n",
        "\n",
        "preds = model.predict(test_fundus)\n",
        "preds = np.argmax(preds, axis=-1)\n",
        "test_true = np.argmax(test_mask, axis=-1)\n",
        "\n",
        "\n",
        "overall_dice = dice_coef_per_class(tf.keras.utils.to_categorical(test_true, 3),\n",
        "                                   tf.keras.utils.to_categorical(preds, 3))\n",
        "print(\"Overall Dice Score:\", overall_dice)\n",
        "\n",
        "\n",
        "groups = {'Asian': [], 'Black': [], 'White': []}\n",
        "race_map = {'0': 'Asian', '1': 'Black', '2': 'White'}\n",
        "\n",
        "for i, info in enumerate(test_data):\n",
        "    race_code = str(info['race']).strip()\n",
        "    race = race_map.get(race_code, None)\n",
        "    if race:\n",
        "        true_mask = tf.keras.utils.to_categorical(test_true[i], 3)\n",
        "        pred_mask = tf.keras.utils.to_categorical(preds[i], 3)\n",
        "        groups[race].append(dice_coef_per_class(true_mask, pred_mask))\n",
        "\n",
        "for g, vals in groups.items():\n",
        "    if vals:\n",
        "        print(f\"{g} Dice Score: {np.mean(vals):.4f}\")\n",
        "    else:\n",
        "        print(f\"{g} Dice Score: No samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNht9JR4IC1U",
        "outputId": "8129d63f-9966-4c6b-a4dd-33bb08a41669"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step\n",
            "Overall Dice Score: 0.8280418347207807\n",
            "Asian Dice Score: 0.8124\n",
            "Black Dice Score: 0.7958\n",
            "White Dice Score: 0.8126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Zh-yhF2-GMHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FCN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def fcn_model(input_shape=(256,256,1), num_classes=3):\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(512, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, 1, activation=\"softmax\")(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "KM_fnYkmZUUY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_fcn = tf.data.Dataset.from_tensor_slices((train_fundus, train_mask))\n",
        "test_fcn  = tf.data.Dataset.from_tensor_slices((test_fundus, test_mask))\n",
        "\n",
        "train_fcn = train_fcn.batch(10).prefetch(tf.data.AUTOTUNE)\n",
        "test_fcn  = test_fcn.batch(10).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "s8moAyXvauiO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_accuracy',\n",
        "    patience = 5,\n",
        "    restore_best_weights = 'True'\n",
        ")\n",
        "\n",
        "model_fcn = fcn_model(input_shape=(256,256,1), num_classes=3)\n",
        "\n",
        "model_fcn.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_fcn = model_fcn.fit(\n",
        "    train_fcn,\n",
        "    validation_data=test_fcn,\n",
        "    epochs=20,\n",
        "    callbacks = [early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3czFfQilZqSl",
        "outputId": "9eb96b04-f967-4f2c-d4ca-27b4ff5d94e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9025 - loss: 0.4192 - val_accuracy: 0.9778 - val_loss: 0.0709\n",
            "Epoch 2/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9789 - loss: 0.0633 - val_accuracy: 0.9831 - val_loss: 0.0485\n",
            "Epoch 3/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9847 - loss: 0.0455 - val_accuracy: 0.9876 - val_loss: 0.0364\n",
            "Epoch 4/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9876 - loss: 0.0363 - val_accuracy: 0.9892 - val_loss: 0.0316\n",
            "Epoch 5/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9888 - loss: 0.0329 - val_accuracy: 0.9899 - val_loss: 0.0289\n",
            "Epoch 6/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9896 - loss: 0.0302 - val_accuracy: 0.9904 - val_loss: 0.0274\n",
            "Epoch 7/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9901 - loss: 0.0282 - val_accuracy: 0.9908 - val_loss: 0.0263\n",
            "Epoch 8/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9906 - loss: 0.0265 - val_accuracy: 0.9911 - val_loss: 0.0251\n",
            "Epoch 9/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0250 - val_accuracy: 0.9914 - val_loss: 0.0243\n",
            "Epoch 10/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0237 - val_accuracy: 0.9917 - val_loss: 0.0234\n",
            "Epoch 11/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9919 - loss: 0.0223 - val_accuracy: 0.9920 - val_loss: 0.0227\n",
            "Epoch 12/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9923 - loss: 0.0211 - val_accuracy: 0.9923 - val_loss: 0.0219\n",
            "Epoch 13/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0202 - val_accuracy: 0.9925 - val_loss: 0.0214\n",
            "Epoch 14/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9929 - loss: 0.0192 - val_accuracy: 0.9927 - val_loss: 0.0208\n",
            "Epoch 15/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9932 - loss: 0.0185 - val_accuracy: 0.9928 - val_loss: 0.0202\n",
            "Epoch 16/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9934 - loss: 0.0178 - val_accuracy: 0.9930 - val_loss: 0.0198\n",
            "Epoch 17/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9936 - loss: 0.0170 - val_accuracy: 0.9931 - val_loss: 0.0196\n",
            "Epoch 18/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9938 - loss: 0.0164 - val_accuracy: 0.9931 - val_loss: 0.0195\n",
            "Epoch 19/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9940 - loss: 0.0158 - val_accuracy: 0.9932 - val_loss: 0.0193\n",
            "Epoch 20/20\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9942 - loss: 0.0153 - val_accuracy: 0.9932 - val_loss: 0.0192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def dice_coef_per_class(y_true, y_pred, smooth=1e-6):\n",
        "    dices = []\n",
        "    for c in range(y_true.shape[-1]):\n",
        "        y_true_f = y_true[..., c].flatten()\n",
        "        y_pred_f = y_pred[..., c].flatten()\n",
        "        intersection = np.sum(y_true_f * y_pred_f)\n",
        "        dice = (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "        dices.append(dice)\n",
        "    return np.mean(dices)\n",
        "\n",
        "preds_fcn = model_fcn.predict(test_fundus)\n",
        "preds_fcn = np.argmax(preds_fcn, axis=-1)\n",
        "test_true_fcn = np.argmax(test_mask, axis=-1)\n",
        "\n",
        "\n",
        "overall_dice_fcn = dice_coef_per_class(\n",
        "    tf.keras.utils.to_categorical(test_true_fcn, 3),\n",
        "    tf.keras.utils.to_categorical(preds_fcn, 3)\n",
        ")\n",
        "print(\"FCN Overall Dice Score:\", overall_dice_fcn)\n",
        "\n",
        "groups_fcn = {'Asian': [], 'Black': [], 'White': []}\n",
        "race_map = {'0': 'Asian', '1': 'Black', '2': 'White'}\n",
        "\n",
        "for i, info in enumerate(test_data):\n",
        "    race_code = str(info['race']).strip()\n",
        "    race = race_map.get(race_code, None)\n",
        "    if race:\n",
        "        true_mask_i = tf.keras.utils.to_categorical(test_true_fcn[i], 3)\n",
        "        pred_mask_i = tf.keras.utils.to_categorical(preds_fcn[i], 3)\n",
        "        groups_fcn[race].append(dice_coef_per_class(true_mask_i, pred_mask_i))\n",
        "\n",
        "for g, vals in groups_fcn.items():\n",
        "    if vals:\n",
        "        print(f\"FCN {g} Dice Score: {np.mean(vals):.4f}\")\n",
        "    else:\n",
        "        print(f\"FCN {g} Dice Score: No samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRjXVySmbRbB",
        "outputId": "1b07ac7a-87c6-4f5a-a9a0-90946125c7dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 206ms/step\n",
            "FCN Overall Dice Score: 0.8663714427632808\n",
            "FCN Asian Dice Score: 0.8503\n",
            "FCN Black Dice Score: 0.8178\n",
            "FCN White Dice Score: 0.8626\n"
          ]
        }
      ]
    }
  ]
}